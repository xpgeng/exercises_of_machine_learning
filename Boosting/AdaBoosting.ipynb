{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x1':[1., 2., 1.3, 1., 2.], 'x2': [2.1, 1.1, 1., 1., 1.], \n",
    "                   'Labels': [1.0, 1.0, -1.0, -1.0, 1.0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datMat = df.loc[:, ['x1', 'x2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Labels   x1   x2\n",
       "0     1.0  1.0  2.1\n",
       "1     1.0  2.0  1.1\n",
       "2    -1.0  1.3  1.0\n",
       "3    -1.0  1.0  1.0\n",
       "4     1.0  2.0  1.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = df.Labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stumpClassify(dataMatrix, dimen, threshVal, threshIneq):\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0], ))\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:, dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:, dimen] > threshVal] = -1.0\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildStump(dataMatrix, labels, D):\n",
    "    '''\n",
    "    '''\n",
    "    # Initial values\n",
    "    m, n = np.shape(dataMatrix)\n",
    "    numSteps = 10.0\n",
    "    bestStump = {}\n",
    "    bestClassEst = np.zeros((m, ))\n",
    "    minError = np.inf\n",
    "    \n",
    "    # for-loop about features\n",
    "    for i in range(n):\n",
    "        rangeMin = dataMatrix[:, i].min()\n",
    "        rangeMax = dataMatrix[:, i].max()\n",
    "        stepSize = (rangeMax - rangeMin)/numSteps\n",
    "        \n",
    "        # for-loop about steps\n",
    "        for j in range(-1, int(numSteps) + 1): # -1 means threshVal less than minVal\n",
    "            \n",
    "            # for-loop about inequality\n",
    "            for inequal in ['lt', 'gt']: # try both less than and greater than  to check the error\n",
    "                \n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)\n",
    "                errArr = np.ones((m, ))\n",
    "                errArr[predictedVals == labels] = 0\n",
    "                weightedError = D.dot(errArr) # scalar value\n",
    "                # print \"split: dim %d, thresh %.2f, thresh ineqal: %s,\\\n",
    "                # the weighted error is %.3f\" % (i, threshVal, inequal, weightedError)\n",
    "                \n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClassEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump, minError, bestClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = np.ones((5, ))/5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: dim 0, thresh 0.90, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 0, thresh 0.90, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 0, thresh 1.00, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 0, thresh 1.00, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 0, thresh 1.10, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 0, thresh 1.10, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 0, thresh 1.20, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 0, thresh 1.20, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 0, thresh 1.30, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.30, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 1.40, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.40, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 1.50, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.50, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 1.60, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.60, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 1.70, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.70, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 1.80, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.80, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 1.90, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.90, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 2.00, thresh ineqal: lt,                the weighted error is 0.600\n",
      "split: dim 0, thresh 2.00, thresh ineqal: gt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 0.89, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 0.89, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.00, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 1, thresh 1.00, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 1, thresh 1.11, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.11, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.22, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.22, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.33, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.33, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.44, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.44, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.55, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.55, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.66, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.66, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.77, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.77, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.88, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.88, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.99, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.99, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 2.10, thresh ineqal: lt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 2.10, thresh ineqal: gt,                the weighted error is 0.400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'ineq': 'lt', 'thresh': 1.3},\n",
       " 0.20000000000000001,\n",
       " array([-1.,  1., -1., -1.,  1.]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildStump(datMat, labels, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaBoostingTrainDS(datMat, labels, numIt=40):\n",
    "    weakClassArr = []\n",
    "    m = np.shape(datMat)[0]\n",
    "    D = np.ones((m, ))/m\n",
    "    aggClassEst = np.zeros((m, ))\n",
    "    for i in range(numIt):\n",
    "        bestStump, error, classEst = buildStump(datMat, labels, D)\n",
    "        # print \"D:\", D\n",
    "        alpha = float(0.5*np.log((1.0-error)/max(error, 1e-16)))\n",
    "        bestStump['alpha'] = alpha\n",
    "        weakClassArr.append(bestStump)\n",
    "        # print \"ClassEst: \", classEst\n",
    "        expon = -1*alpha*labels*classEst\n",
    "        D = D*np.exp(expon)\n",
    "        D = D/D.sum()\n",
    "        aggClassEst += alpha*classEst\n",
    "        # print \"aggClassEst: \", aggClassEst\n",
    "        aggErrors = (np.sign(aggClassEst) != labels) * np.ones((m, ))\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        print \"total error:\", errorRate, \"\\n\"\n",
    "        if errorRate == 0.0:\n",
    "            break\n",
    "    return weakClassArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: dim 0, thresh 0.90, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 0, thresh 0.90, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 0, thresh 1.00, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 0, thresh 1.00, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 0, thresh 1.10, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 0, thresh 1.10, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 0, thresh 1.20, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 0, thresh 1.20, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 0, thresh 1.30, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.30, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 1.40, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.40, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 1.50, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.50, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 1.60, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.60, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 1.70, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.70, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 1.80, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.80, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 1.90, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 0, thresh 1.90, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 0, thresh 2.00, thresh ineqal: lt,                the weighted error is 0.600\n",
      "split: dim 0, thresh 2.00, thresh ineqal: gt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 0.89, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 0.89, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.00, thresh ineqal: lt,                the weighted error is 0.200\n",
      "split: dim 1, thresh 1.00, thresh ineqal: gt,                the weighted error is 0.800\n",
      "split: dim 1, thresh 1.11, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.11, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.22, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.22, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.33, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.33, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.44, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.44, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.55, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.55, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.66, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.66, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.77, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.77, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.88, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.88, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 1.99, thresh ineqal: lt,                the weighted error is 0.400\n",
      "split: dim 1, thresh 1.99, thresh ineqal: gt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 2.10, thresh ineqal: lt,                the weighted error is 0.600\n",
      "split: dim 1, thresh 2.10, thresh ineqal: gt,                the weighted error is 0.400\n",
      "D: [ 0.2  0.2  0.2  0.2  0.2]\n",
      "ClassEst:  [-1.  1. -1. -1.  1.]\n",
      "aggClassEst:  [-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]\n",
      "total error: 0.2 \n",
      "\n",
      "split: dim 0, thresh 0.90, thresh ineqal: lt,                the weighted error is 0.250\n",
      "split: dim 0, thresh 0.90, thresh ineqal: gt,                the weighted error is 0.750\n",
      "split: dim 0, thresh 1.00, thresh ineqal: lt,                the weighted error is 0.625\n",
      "split: dim 0, thresh 1.00, thresh ineqal: gt,                the weighted error is 0.375\n",
      "split: dim 0, thresh 1.10, thresh ineqal: lt,                the weighted error is 0.625\n",
      "split: dim 0, thresh 1.10, thresh ineqal: gt,                the weighted error is 0.375\n",
      "split: dim 0, thresh 1.20, thresh ineqal: lt,                the weighted error is 0.625\n",
      "split: dim 0, thresh 1.20, thresh ineqal: gt,                the weighted error is 0.375\n",
      "split: dim 0, thresh 1.30, thresh ineqal: lt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.30, thresh ineqal: gt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.40, thresh ineqal: lt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.40, thresh ineqal: gt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.50, thresh ineqal: lt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.50, thresh ineqal: gt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.60, thresh ineqal: lt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.60, thresh ineqal: gt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.70, thresh ineqal: lt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.70, thresh ineqal: gt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.80, thresh ineqal: lt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.80, thresh ineqal: gt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.90, thresh ineqal: lt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 1.90, thresh ineqal: gt,                the weighted error is 0.500\n",
      "split: dim 0, thresh 2.00, thresh ineqal: lt,                the weighted error is 0.750\n",
      "split: dim 0, thresh 2.00, thresh ineqal: gt,                the weighted error is 0.250\n",
      "split: dim 1, thresh 0.89, thresh ineqal: lt,                the weighted error is 0.250\n",
      "split: dim 1, thresh 0.89, thresh ineqal: gt,                the weighted error is 0.750\n",
      "split: dim 1, thresh 1.00, thresh ineqal: lt,                the weighted error is 0.125\n",
      "split: dim 1, thresh 1.00, thresh ineqal: gt,                the weighted error is 0.875\n",
      "split: dim 1, thresh 1.11, thresh ineqal: lt,                the weighted error is 0.250\n",
      "split: dim 1, thresh 1.11, thresh ineqal: gt,                the weighted error is 0.750\n",
      "split: dim 1, thresh 1.22, thresh ineqal: lt,                the weighted error is 0.250\n",
      "split: dim 1, thresh 1.22, thresh ineqal: gt,                the weighted error is 0.750\n",
      "split: dim 1, thresh 1.33, thresh ineqal: lt,                the weighted error is 0.250\n",
      "split: dim 1, thresh 1.33, thresh ineqal: gt,                the weighted error is 0.750\n",
      "split: dim 1, thresh 1.44, thresh ineqal: lt,                the weighted error is 0.250\n",
      "split: dim 1, thresh 1.44, thresh ineqal: gt,                the weighted error is 0.750\n",
      "split: dim 1, thresh 1.55, thresh ineqal: lt,                the weighted error is 0.250\n",
      "split: dim 1, thresh 1.55, thresh ineqal: gt,                the weighted error is 0.750\n",
      "split: dim 1, thresh 1.66, thresh ineqal: lt,                the weighted error is 0.250\n",
      "split: dim 1, thresh 1.66, thresh ineqal: gt,                the weighted error is 0.750\n",
      "split: dim 1, thresh 1.77, thresh ineqal: lt,                the weighted error is 0.250\n",
      "split: dim 1, thresh 1.77, thresh ineqal: gt,                the weighted error is 0.750\n",
      "split: dim 1, thresh 1.88, thresh ineqal: lt,                the weighted error is 0.250\n",
      "split: dim 1, thresh 1.88, thresh ineqal: gt,                the weighted error is 0.750\n",
      "split: dim 1, thresh 1.99, thresh ineqal: lt,                the weighted error is 0.250\n",
      "split: dim 1, thresh 1.99, thresh ineqal: gt,                the weighted error is 0.750\n",
      "split: dim 1, thresh 2.10, thresh ineqal: lt,                the weighted error is 0.750\n",
      "split: dim 1, thresh 2.10, thresh ineqal: gt,                the weighted error is 0.250\n",
      "D: [ 0.5    0.125  0.125  0.125  0.125]\n",
      "ClassEst:  [ 1.  1. -1. -1. -1.]\n",
      "aggClassEst:  [ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]\n",
      "total error: 0.2 \n",
      "\n",
      "split: dim 0, thresh 0.90, thresh ineqal: lt,                the weighted error is 0.143\n",
      "split: dim 0, thresh 0.90, thresh ineqal: gt,                the weighted error is 0.857\n",
      "split: dim 0, thresh 1.00, thresh ineqal: lt,                the weighted error is 0.357\n",
      "split: dim 0, thresh 1.00, thresh ineqal: gt,                the weighted error is 0.643\n",
      "split: dim 0, thresh 1.10, thresh ineqal: lt,                the weighted error is 0.357\n",
      "split: dim 0, thresh 1.10, thresh ineqal: gt,                the weighted error is 0.643\n",
      "split: dim 0, thresh 1.20, thresh ineqal: lt,                the weighted error is 0.357\n",
      "split: dim 0, thresh 1.20, thresh ineqal: gt,                the weighted error is 0.643\n",
      "split: dim 0, thresh 1.30, thresh ineqal: lt,                the weighted error is 0.286\n",
      "split: dim 0, thresh 1.30, thresh ineqal: gt,                the weighted error is 0.714\n",
      "split: dim 0, thresh 1.40, thresh ineqal: lt,                the weighted error is 0.286\n",
      "split: dim 0, thresh 1.40, thresh ineqal: gt,                the weighted error is 0.714\n",
      "split: dim 0, thresh 1.50, thresh ineqal: lt,                the weighted error is 0.286\n",
      "split: dim 0, thresh 1.50, thresh ineqal: gt,                the weighted error is 0.714\n",
      "split: dim 0, thresh 1.60, thresh ineqal: lt,                the weighted error is 0.286\n",
      "split: dim 0, thresh 1.60, thresh ineqal: gt,                the weighted error is 0.714\n",
      "split: dim 0, thresh 1.70, thresh ineqal: lt,                the weighted error is 0.286\n",
      "split: dim 0, thresh 1.70, thresh ineqal: gt,                the weighted error is 0.714\n",
      "split: dim 0, thresh 1.80, thresh ineqal: lt,                the weighted error is 0.286\n",
      "split: dim 0, thresh 1.80, thresh ineqal: gt,                the weighted error is 0.714\n",
      "split: dim 0, thresh 1.90, thresh ineqal: lt,                the weighted error is 0.286\n",
      "split: dim 0, thresh 1.90, thresh ineqal: gt,                the weighted error is 0.714\n",
      "split: dim 0, thresh 2.00, thresh ineqal: lt,                the weighted error is 0.857\n",
      "split: dim 0, thresh 2.00, thresh ineqal: gt,                the weighted error is 0.143\n",
      "split: dim 1, thresh 0.89, thresh ineqal: lt,                the weighted error is 0.143\n",
      "split: dim 1, thresh 0.89, thresh ineqal: gt,                the weighted error is 0.857\n",
      "split: dim 1, thresh 1.00, thresh ineqal: lt,                the weighted error is 0.500\n",
      "split: dim 1, thresh 1.00, thresh ineqal: gt,                the weighted error is 0.500\n",
      "split: dim 1, thresh 1.11, thresh ineqal: lt,                the weighted error is 0.571\n",
      "split: dim 1, thresh 1.11, thresh ineqal: gt,                the weighted error is 0.429\n",
      "split: dim 1, thresh 1.22, thresh ineqal: lt,                the weighted error is 0.571\n",
      "split: dim 1, thresh 1.22, thresh ineqal: gt,                the weighted error is 0.429\n",
      "split: dim 1, thresh 1.33, thresh ineqal: lt,                the weighted error is 0.571\n",
      "split: dim 1, thresh 1.33, thresh ineqal: gt,                the weighted error is 0.429\n",
      "split: dim 1, thresh 1.44, thresh ineqal: lt,                the weighted error is 0.571\n",
      "split: dim 1, thresh 1.44, thresh ineqal: gt,                the weighted error is 0.429\n",
      "split: dim 1, thresh 1.55, thresh ineqal: lt,                the weighted error is 0.571\n",
      "split: dim 1, thresh 1.55, thresh ineqal: gt,                the weighted error is 0.429\n",
      "split: dim 1, thresh 1.66, thresh ineqal: lt,                the weighted error is 0.571\n",
      "split: dim 1, thresh 1.66, thresh ineqal: gt,                the weighted error is 0.429\n",
      "split: dim 1, thresh 1.77, thresh ineqal: lt,                the weighted error is 0.571\n",
      "split: dim 1, thresh 1.77, thresh ineqal: gt,                the weighted error is 0.429\n",
      "split: dim 1, thresh 1.88, thresh ineqal: lt,                the weighted error is 0.571\n",
      "split: dim 1, thresh 1.88, thresh ineqal: gt,                the weighted error is 0.429\n",
      "split: dim 1, thresh 1.99, thresh ineqal: lt,                the weighted error is 0.571\n",
      "split: dim 1, thresh 1.99, thresh ineqal: gt,                the weighted error is 0.429\n",
      "split: dim 1, thresh 2.10, thresh ineqal: lt,                the weighted error is 0.857\n",
      "split: dim 1, thresh 2.10, thresh ineqal: gt,                the weighted error is 0.143\n",
      "D: [ 0.28571429  0.07142857  0.07142857  0.07142857  0.5       ]\n",
      "ClassEst:  [ 1.  1.  1.  1.  1.]\n",
      "aggClassEst:  [ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]\n",
      "total error: 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifierArray = adaBoostingTrainDS(datMat, labels, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alpha': 0.6931471805599453, 'dim': 0, 'ineq': 'lt', 'thresh': 1.3},\n",
       " {'alpha': 0.9729550745276565, 'dim': 1, 'ineq': 'lt', 'thresh': 1.0},\n",
       " {'alpha': 0.8958797346140273,\n",
       "  'dim': 0,\n",
       "  'ineq': 'lt',\n",
       "  'thresh': 0.90000000000000002}]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaClassify(dataMatrix, classifierArr):\n",
    "    m = np.shape(dataMatrix)[0]\n",
    "    aggClassEst = np.zeros((m, ))\n",
    "    for i in range(len(classifierArray)):\n",
    "        classEst = stumpClassify(dataMatrix, classifierArray[i]['dim'],\n",
    "                                classifierArray[i]['thresh'], classifierArray[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "        print aggClassEst\n",
    "    return np.sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datMat = np.array([[0., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.69314718]\n",
      "[-1.66610226]\n",
      "[-2.56198199]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify(test_datMat, classifierArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horse colic dataset using AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_horse = pd.read_csv('Horse_colic_dataset/horseColicTraining2.txt', sep='\\t', names=np.arange(22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datMat_horse = df_horse.values[:, 0: 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_horse = df_horse.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 0.284280936455 \n",
      "\n",
      "total error: 0.284280936455 \n",
      "\n",
      "total error: 0.247491638796 \n",
      "\n",
      "total error: 0.247491638796 \n",
      "\n",
      "total error: 0.254180602007 \n",
      "\n",
      "total error: 0.240802675585 \n",
      "\n",
      "total error: 0.240802675585 \n",
      "\n",
      "total error: 0.220735785953 \n",
      "\n",
      "total error: 0.247491638796 \n",
      "\n",
      "total error: 0.230769230769 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifierArray = adaBoostingTrainDS(datMat_horse, labels_horse, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('Horse_colic_dataset/horseColicTest2.txt', sep='\\t', names=np.arange(22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datMat_test = df_test.values[:, 0: 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_test = df_test.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.46166238  0.46166238 -0.46166238 -0.46166238  0.46166238  0.46166238\n",
      "  0.46166238  0.46166238  0.46166238  0.46166238  0.46166238 -0.46166238\n",
      " -0.46166238  0.46166238  0.46166238  0.46166238  0.46166238 -0.46166238\n",
      " -0.46166238 -0.46166238 -0.46166238  0.46166238 -0.46166238 -0.46166238\n",
      "  0.46166238  0.46166238  0.46166238  0.46166238  0.46166238  0.46166238\n",
      "  0.46166238  0.46166238 -0.46166238  0.46166238  0.46166238  0.46166238\n",
      "  0.46166238  0.46166238  0.46166238  0.46166238  0.46166238  0.46166238\n",
      "  0.46166238  0.46166238  0.46166238  0.46166238 -0.46166238  0.46166238\n",
      " -0.46166238  0.46166238  0.46166238  0.46166238  0.46166238  0.46166238\n",
      "  0.46166238  0.46166238  0.46166238 -0.46166238  0.46166238 -0.46166238\n",
      "  0.46166238  0.46166238 -0.46166238  0.46166238  0.46166238  0.46166238\n",
      "  0.46166238]\n",
      "[ 0.77414483  0.77414483 -0.14917993 -0.14917993  0.77414483  0.77414483\n",
      "  0.14917993  0.77414483  0.77414483  0.14917993  0.14917993 -0.14917993\n",
      " -0.14917993  0.77414483  0.77414483  0.77414483  0.77414483 -0.14917993\n",
      " -0.14917993 -0.77414483 -0.14917993  0.77414483 -0.14917993 -0.77414483\n",
      "  0.77414483  0.77414483  0.77414483  0.77414483  0.77414483  0.77414483\n",
      "  0.77414483  0.14917993 -0.14917993  0.77414483  0.77414483  0.77414483\n",
      "  0.77414483  0.77414483  0.77414483  0.77414483  0.77414483  0.77414483\n",
      "  0.77414483  0.14917993  0.14917993  0.77414483 -0.14917993  0.77414483\n",
      " -0.14917993  0.14917993  0.14917993  0.77414483  0.77414483  0.77414483\n",
      "  0.77414483  0.77414483  0.14917993 -0.14917993  0.77414483 -0.77414483\n",
      "  0.77414483  0.14917993 -0.14917993  0.77414483  0.77414483  0.77414483\n",
      "  0.77414483]\n",
      "[ 1.06095456  1.06095456  0.1376298  -0.43598966  1.06095456  0.4873351\n",
      " -0.1376298   1.06095456  1.06095456 -0.1376298  -0.1376298  -0.43598966\n",
      " -0.43598966  0.4873351   0.4873351   0.4873351   1.06095456 -0.43598966\n",
      " -0.43598966 -1.06095456 -0.43598966  1.06095456 -0.43598966 -1.06095456\n",
      "  1.06095456  1.06095456  1.06095456  0.4873351   1.06095456  0.4873351\n",
      "  1.06095456 -0.1376298  -0.43598966  0.4873351   0.4873351   1.06095456\n",
      "  1.06095456  1.06095456  1.06095456  0.4873351   1.06095456  1.06095456\n",
      "  1.06095456 -0.1376298  -0.1376298   0.4873351  -0.43598966  1.06095456\n",
      "  0.1376298  -0.1376298  -0.1376298   0.4873351   1.06095456  1.06095456\n",
      "  1.06095456  1.06095456  0.43598966  0.1376298   0.4873351  -1.06095456\n",
      "  1.06095456 -0.1376298  -0.43598966  1.06095456  0.4873351   1.06095456\n",
      "  0.4873351 ]\n",
      "[ 0.82798452  0.82798452  0.37059985 -0.66895971  0.82798452  0.72030514\n",
      " -0.37059985  0.82798452  0.82798452 -0.37059985 -0.37059985 -0.20301961\n",
      " -0.66895971  0.25436505  0.25436505  0.25436505  0.82798452 -0.66895971\n",
      " -0.66895971 -0.82798452 -0.66895971  0.82798452 -0.66895971 -1.29392461\n",
      "  1.29392461  0.82798452  1.29392461  0.25436505  0.82798452  0.25436505\n",
      "  0.82798452 -0.37059985 -0.66895971  0.25436505  0.25436505  0.82798452\n",
      "  0.82798452  0.82798452  0.82798452  0.72030514  0.82798452  0.82798452\n",
      "  0.82798452 -0.37059985 -0.37059985  0.25436505 -0.66895971  0.82798452\n",
      "  0.37059985  0.09534024 -0.37059985  0.72030514  1.29392461  0.82798452\n",
      "  0.82798452  0.82798452  0.66895971 -0.09534024  0.72030514 -1.29392461\n",
      "  0.82798452 -0.37059985 -0.66895971  0.82798452  0.72030514  0.82798452\n",
      "  0.25436505]\n",
      "[ 1.02602298  1.02602298  0.56863831 -0.47092125  0.62994605  0.91834361\n",
      " -0.17256139  0.62994605  1.02602298 -0.17256139 -0.17256139 -0.00498115\n",
      " -0.47092125  0.05632659  0.45240351  0.45240351  1.02602298 -0.47092125\n",
      " -0.47092125 -0.62994605 -0.47092125  1.02602298 -0.47092125 -1.09588615\n",
      "  1.49196307  1.02602298  1.49196307  0.45240351  1.02602298  0.45240351\n",
      "  1.02602298 -0.17256139 -0.47092125  0.05632659  0.05632659  1.02602298\n",
      "  1.02602298  1.02602298  1.02602298  0.91834361  1.02602298  1.02602298\n",
      "  1.02602298 -0.17256139 -0.56863831  0.45240351 -0.47092125  1.02602298\n",
      "  0.56863831  0.2933787  -0.17256139  0.91834361  1.49196307  1.02602298\n",
      "  0.62994605  1.02602298  0.86699817  0.10269822  0.91834361 -1.09588615\n",
      "  1.02602298 -0.17256139 -0.47092125  1.02602298  0.91834361  1.02602298\n",
      "  0.45240351]\n",
      "[ 1.21450185  1.21450185  0.75711718 -0.65940012  0.44146718  0.72986473\n",
      " -0.36104026  0.81842493  0.8375441  -0.36104026 -0.36104026  0.18349772\n",
      " -0.65940012  0.24480546  0.64088239  0.64088239  0.8375441  -0.28244237\n",
      " -0.65940012 -0.44146718 -0.65940012  0.8375441  -0.65940012 -1.28436502\n",
      "  1.68044194  1.21450185  1.68044194  0.64088239  1.21450185  0.64088239\n",
      "  1.21450185 -0.36104026 -0.28244237  0.24480546 -0.13215228  0.8375441\n",
      "  1.21450185  1.21450185  1.21450185  0.72986473  0.8375441   1.21450185\n",
      "  1.21450185 -0.36104026 -0.38015944  0.26392464 -0.65940012  0.8375441\n",
      "  0.38015944  0.10489983 -0.36104026  1.10682248  1.68044194  1.21450185\n",
      "  0.81842493  0.8375441   0.6785193  -0.08578066  1.10682248 -0.90740727\n",
      "  0.8375441  -0.36104026 -0.28244237  1.21450185  1.10682248  0.8375441\n",
      "  0.26392464]\n",
      "[ 1.36677554  1.06222816  0.60484349 -0.81167381  0.28919349  0.88213842\n",
      " -0.20876657  0.97069862  0.98981779 -0.51331395 -0.20876657  0.03122403\n",
      " -0.50712643  0.39707915  0.79315608  0.79315608  0.68527041 -0.43471606\n",
      " -0.81167381 -0.59374087 -0.50712643  0.98981779 -0.50712643 -1.43663871\n",
      "  1.52816825  1.06222816  1.83271563  0.4886087   1.06222816  0.4886087\n",
      "  1.36677554 -0.20876657 -0.43471606  0.09253177 -0.28442597  0.68527041\n",
      "  1.06222816  1.06222816  1.06222816  0.88213842  0.98981779  1.36677554\n",
      "  1.06222816 -0.51331395 -0.53243313  0.11165095 -0.50712643  0.68527041\n",
      "  0.22788575 -0.04737386 -0.51331395  0.95454879  1.52816825  1.06222816\n",
      "  0.66615124  0.98981779  0.52624561 -0.23805435  1.25909617 -1.05968096\n",
      "  0.98981779 -0.51331395 -0.43471606  1.06222816  0.95454879  0.68527041\n",
      "  0.11165095]\n",
      "[ 1.21166683  1.21733687  0.44973479 -0.96678252  0.13408478  1.03724713\n",
      " -0.36387528  0.81558991  0.83470909 -0.66842266 -0.36387528 -0.12388468\n",
      " -0.66223514  0.24197045  0.63804737  0.94826478  0.84037912 -0.58982477\n",
      " -0.96678252 -0.74884958 -0.66223514  0.83470909 -0.66223514 -1.59174742\n",
      "  1.68327696  0.90711945  1.67760692  0.33349999  1.21733687  0.6437174\n",
      "  1.52188425 -0.36387528 -0.58982477 -0.06257693 -0.43953468  0.84037912\n",
      "  1.21733687  1.21733687  0.90711945  0.72702971  0.83470909  1.21166683\n",
      "  0.90711945 -0.66842266 -0.68754184 -0.04345776 -0.66223514  0.84037912\n",
      "  0.38299446 -0.20248257 -0.66842266  0.79944008  1.37305954  1.21733687\n",
      "  0.82125995  1.1449265   0.68135431 -0.39316305  1.10398746 -1.21478967\n",
      "  1.1449265  -0.66842266 -0.58982477  1.21733687  0.79944008  0.53016171\n",
      "  0.26675966]\n",
      "[ 1.07630486  1.0819749   0.31437281 -0.83142054  0.26944676  1.1726091\n",
      " -0.22851331  0.95095188  0.97007106 -0.53306069 -0.22851331 -0.25924665\n",
      " -0.52687316  0.37733242  0.77340934  1.08362676  0.9757411  -0.4544628\n",
      " -0.83142054 -0.88421155 -0.52687316  0.97007106 -0.52687316 -1.45638544\n",
      "  1.81863893  1.04248143  1.8129689   0.46886196  1.35269884  0.50835543\n",
      "  1.65724622 -0.22851331 -0.4544628  -0.19793891 -0.30417271  0.9757411\n",
      "  1.35269884  1.35269884  1.04248143  0.86239169  0.97007106  1.34702881\n",
      "  1.04248143 -0.53306069 -0.55217986  0.09190421 -0.52687316  0.9757411\n",
      "  0.51835643 -0.06712059 -0.53306069  0.93480205  1.50842152  1.35269884\n",
      "  0.68589797  1.28028848  0.81671629 -0.25780108  1.23934943 -1.0794277\n",
      "  1.28028848 -0.53306069 -0.4544628   1.35269884  0.93480205  0.66552368\n",
      "  0.40212163]\n",
      "[ 0.95108899  1.20719077  0.18915694 -0.95663642  0.14423088  1.29782498\n",
      " -0.10329743  0.82573601  1.09528693 -0.65827656 -0.35372918 -0.38446252\n",
      " -0.40165729  0.50254829  0.64819347  1.20884263  0.85052522 -0.57967867\n",
      " -0.70620467 -0.75899568 -0.65208904  1.09528693 -0.40165729 -1.33116957\n",
      "  1.69342306  1.1676973   1.68775303  0.34364609  1.22748297  0.38313956\n",
      "  1.53203035 -0.35372918 -0.57967867 -0.32315478 -0.17895684  0.85052522\n",
      "  1.22748297  1.22748297  0.91726555  0.98760756  0.84485519  1.47224468\n",
      "  0.91726555 -0.65827656 -0.67739574  0.21712009 -0.40165729  0.85052522\n",
      "  0.39314056  0.05809528 -0.40784481  0.80958618  1.63363739  1.22748297\n",
      "  0.81111385  1.1550726   0.69150041 -0.38301695  1.11413356 -1.20464357\n",
      "  1.1550726  -0.40784481 -0.32924692  1.47791472  0.80958618  0.54030781\n",
      "  0.5273375 ]\n"
     ]
    }
   ],
   "source": [
    "prediction = adaClassify(datMat_test, classifierArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errArr = np.ones((67, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23880597014925373"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errArr[prediction != labels_test].sum()/67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
